import os
import streamlit as st
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_pinecone import PineconeVectorStore
from langchain.chains import RetrievalQA
from pinecone import Pinecone

# .env èª­ã¿è¾¼ã¿
load_dotenv()

# API ã‚­ãƒ¼å–å¾—
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_INDEX_NAME = os.getenv("PINECONE_INDEX_NAME")

# ãƒã‚§ãƒƒã‚¯
if not all([OPENAI_API_KEY, PINECONE_API_KEY, PINECONE_INDEX_NAME]):
    st.error("â— .env ãƒ•ã‚¡ã‚¤ãƒ«ã« API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

# ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢åˆæœŸåŒ–
embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)
pc = Pinecone(api_key=PINECONE_API_KEY)
index = pc.Index(PINECONE_INDEX_NAME)
vectorstore = PineconeVectorStore(index=index, embedding=embeddings, text_key="text")

# LLM + RAG ãƒã‚§ãƒ¼ãƒ³
llm = ChatOpenAI(api_key=OPENAI_API_KEY, model="gpt-3.5-turbo")
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    return_source_documents=True
)

# âœ… ì„¸ì…˜ ì´ˆê¸°í™” í•¨ìˆ˜
def reset_inputs():
    for key in ["lost_item", "brand", "lost_date", "lost_place", "lost_color", "features"]:
        if key in st.session_state:
             del st.session_state[key]
    st.rerun() 
    
# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="RAG è½ã¨ã—ç‰©æ¤œç´¢", page_icon="ğŸ”")
st.title("ğŸ” è½ã¨ã—ç‰© RAG æ¤œç´¢ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹")

# ì…ë ¥ í•„ë“œ (ê° ì…ë ¥ì— ê³ ìœ  keyë¥¼ ì¤Œ)
st.text_input("ğŸ“¦ ç´›å¤±ç‰©ã®åå‰", key="lost_item")
st.text_input("ğŸ·ï¸ ãƒ–ãƒ©ãƒ³ãƒ‰å", key="brand")
st.text_input("ğŸ“… ç´›å¤±æ—¥", key="lost_date")
st.text_input("ğŸ“ ç´›å¤±å ´æ‰€", key="lost_place")
st.text_input("ğŸ¨ è‰²", key="lost_color")
st.text_area("ğŸ§· ç‰¹å¾´ï¼ˆè©³ç´°ï¼‰", key="features")

# ğŸ”„ ãƒªã‚»ãƒƒãƒˆ ë²„íŠ¼ (ìœ„ì—)
if st.button("ğŸ”„ ãƒªã‚»ãƒƒãƒˆ"):
    reset_inputs()

# ğŸ” æ¤œç´¢ã™ã‚‹ ë²„íŠ¼ (ì•„ë˜ì—)
if st.button("ğŸ” æ¤œç´¢ã™ã‚‹"):
    query_parts = [
        f"ç´›å¤±ç‰©: {st.session_state.lost_item}" if st.session_state.lost_item else "",
        f"ãƒ–ãƒ©ãƒ³ãƒ‰: {st.session_state.brand}" if st.session_state.brand else "",
        f"æ—¥ä»˜: {st.session_state.lost_date}" if st.session_state.lost_date else "",
        f"å ´æ‰€: {st.session_state.lost_place}" if st.session_state.lost_place else "",
        f"è‰²: {st.session_state.lost_color}" if st.session_state.lost_color else "",
        f"ç‰¹å¾´: {st.session_state.features}" if st.session_state.features else ""
    ]
    query = " / ".join(filter(None, query_parts))

    with st.spinner("ğŸ“¡ RAG æ¤œç´¢ä¸­..."):
        result = qa_chain.invoke({"query": query})
        st.success("âœ… é¡ä¼¼ã™ã‚‹ã‚¢ã‚¤ãƒ†ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼")

        st.subheader("ğŸ” æ¤œç´¢çµæœ")
        st.write(result["result"])

        with st.expander("ğŸ“„ å‚ç…§ã•ã‚ŒãŸå…ƒæ–‡æ›¸ã‚’è¡¨ç¤º"):
            for i, doc in enumerate(result.get("source_documents", [])):
                st.markdown(f"**æ–‡æ›¸ {i+1}:**")
                st.code(doc.page_content, language="text")





# import os
# import streamlit as st
# from dotenv import load_dotenv
# from langchain_openai import OpenAIEmbeddings, ChatOpenAI
# from langchain_pinecone import PineconeVectorStore
# from langchain.chains import RetrievalQA
# from pinecone import Pinecone

# # .env èª­ã¿è¾¼ã¿
# load_dotenv()

# # API ã‚­ãƒ¼å–å¾—
# OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
# PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
# PINECONE_INDEX_NAME = os.getenv("PINECONE_INDEX_NAME")

# # ãƒã‚§ãƒƒã‚¯
# if not all([OPENAI_API_KEY, PINECONE_API_KEY, PINECONE_INDEX_NAME]):
#     st.error("â— .env ãƒ•ã‚¡ã‚¤ãƒ«ã« API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
#     st.stop()

# # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢åˆæœŸåŒ–
# embeddings = OpenAIEmbeddings(api_key=OPENAI_API_KEY)
# pc = Pinecone(api_key=PINECONE_API_KEY)
# index = pc.Index(PINECONE_INDEX_NAME)
# vectorstore = PineconeVectorStore(index=index, embedding=embeddings, text_key="text")

# # LLM + RAG ãƒã‚§ãƒ¼ãƒ³
# llm = ChatOpenAI(api_key=OPENAI_API_KEY, model="gpt-3.5-turbo")
# retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
# qa_chain = RetrievalQA.from_chain_type(
#     llm=llm,
#     retriever=retriever,
#     return_source_documents=True
# )

# # Streamlit UI
# st.set_page_config(page_title="RAG è½ã¨ã—ç‰©æ¤œç´¢", page_icon="ğŸ”")
# st.title("ğŸ” è½ã¨ã—ç‰© RAG æ¤œç´¢ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹")

# # å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
# lost_item = st.text_input("ğŸ“¦ ç´›å¤±ç‰©ã®åå‰", key="lost_item")
# brand = st.text_input("ğŸ·ï¸ ãƒ–ãƒ©ãƒ³ãƒ‰å", key="brand")
# lost_date = st.text_input("ğŸ“… ç´›å¤±æ—¥", key="lost_date")
# lost_place = st.text_input("ğŸ“ ç´›å¤±å ´æ‰€", key="lost_place")
# lost_color = st.text_input("ğŸ¨ è‰²", key="lost_color")
# features = st.text_area("ğŸ§· ç‰¹å¾´ï¼ˆè©³ç´°ï¼‰", key="features")

# # ğŸ‘‡ ë¦¬ì…‹ í•¨ìˆ˜ ì •ì˜
# def reset_fields():
#     for key in ["lost_item", "brand", "lost_date", "lost_place", "lost_color", "features"]:
#         if key in st.session_state:
#             del st.session_state[key]
#     st.experimental_rerun()

# # ğŸ”æ¤œç´¢ ï¼† ğŸ”„ãƒªã‚»ãƒƒãƒˆ ãƒœã‚¿ãƒ³
# btn_col1, btn_col2 = st.columns([1, 4])

# with btn_col1:
#     search_clicked = st.button("ğŸ” æ¤œç´¢ã™ã‚‹")

# with btn_col2:
#     st.button("ğŸ”„ ãƒªã‚»ãƒƒãƒˆ", on_click=reset_fields)

# # æ¤œç´¢å‡¦ç†
# if search_clicked:
#     query_parts = [
#         f"ç´›å¤±ç‰©: {lost_item}" if lost_item else "",
#         f"ãƒ–ãƒ©ãƒ³ãƒ‰: {brand}" if brand else "",
#         f"æ—¥ä»˜: {lost_date}" if lost_date else "",
#         f"å ´æ‰€: {lost_place}" if lost_place else "",
#         f"è‰²: {lost_color}" if lost_color else "",
#         f"ç‰¹å¾´: {features}" if features else ""
#     ]
#     query = " / ".join(filter(None, query_parts))

#     with st.spinner("ğŸ“¡ RAG æ¤œç´¢ä¸­..."):
#         result = qa_chain.invoke({"query": query})
#         st.success("âœ… é¡ä¼¼ã™ã‚‹ã‚¢ã‚¤ãƒ†ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼")

#         # çµæœè¡¨ç¤º
#         st.subheader("ğŸ” æ¤œç´¢çµæœ")
#         st.write(result["result"])

#         # ã‚½ãƒ¼ã‚¹è¡¨ç¤º
#         with st.expander("ğŸ“„ å‚ç…§ã•ã‚ŒãŸå…ƒæ–‡æ›¸ã‚’è¡¨ç¤º"):
#             for i, doc in enumerate(result.get("source_documents", [])):
#                 st.markdown(f"**æ–‡æ›¸ {i+1}:**")
#                 st.code(doc.page_content, language="text")



# streamlit run "c:/Users/kwskm/OneDrive/ë°”íƒ• í™”ë©´/RAG/test-match.py"

